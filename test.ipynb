{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 21:54:18,877 - INFO - Event loop is already running. Using create_task instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 21:54:18,882 - DEBUG - Tools: {\n",
      "  \"type\": \"function\",\n",
      "  \"function\": {\n",
      "    \"name\": \"issueresolution\",\n",
      "    \"description\": \"Identify if Issue resolution is relevant\",\n",
      "    \"parameters\": {\n",
      "      \"properties\": {\n",
      "        \"description\": {\n",
      "          \"description\": \"Issue resolution\",\n",
      "          \"title\": \"Description\",\n",
      "          \"type\": \"string\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"description\"\n",
      "      ],\n",
      "      \"title\": \"issueresolution\",\n",
      "      \"type\": \"object\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "2025-05-12 21:54:19,048 - DEBUG - Patching `client.chat.completions.create` with mode=<Mode.PARALLEL_TOOLS: 'parallel_tool_call'>\n",
      "2025-05-12 21:54:19,049 - INFO - ResponseHandler initialized with client: <llm_client.clients.openai_client.OpenAICompletionClient object at 0x12e54f200> and settings: {'provider': 'openai', 'model': 'gpt-4o-mini', 'temperature': 0, 'max_tokens': 1000, 'mode': 'PARALLEL_TOOLS', 'tool_choice': 'required'}\n",
      "2025-05-12 21:54:19,049 - INFO - Client and handler initialized successfully.\n",
      "2025-05-12 21:54:19,062 - DEBUG - Top-level model cache MISS for schema_hash=0a8cbc26bbfc674722d6a07451d535b6\n",
      "2025-05-12 21:54:19,068 - DEBUG - Building sub-model 'issueresolution' from schema. key=submodel:87c67c6ae2f88c87f0bced3cd07dacd5\n",
      "2025-05-12 21:54:19,080 - DEBUG - Top-level model cache MISS for schema_hash=54927f24b8730b3a4e1f0e158babd396\n",
      "2025-05-12 21:54:19,083 - DEBUG - Building sub-model 'damagedproduct' from schema. key=submodel:6bbebd1a8c861d374e2a4480d95d26eb\n",
      "2025-05-12 21:54:19,084 - DEBUG - Top-level model cache MISS for schema_hash=94f44e2b961eeec8c6e1e1838ed126eb\n",
      "2025-05-12 21:54:19,084 - DEBUG - Building sub-model 'poorcustomersupport' from schema. key=submodel:2a5a53ea9d2ebd114d5b0c6dfcade2a5\n",
      "2025-05-12 21:54:19,085 - DEBUG - Top-level model cache MISS for schema_hash=4a34b9907d97109aa93459d7f4a1b17e\n",
      "2025-05-12 21:54:19,086 - DEBUG - Building sub-model 'refunddelay' from schema. key=submodel:2ad6b0bed1978a03dfd4729b8dcc3b03\n",
      "2025-05-12 21:54:19,086 - DEBUG - Top-level model cache MISS for schema_hash=649913603b75bd142bf3e4e6a02d056a\n",
      "2025-05-12 21:54:19,087 - DEBUG - Building sub-model 'agentcommunicationissues' from schema. key=submodel:5cd285a689026a2188488a7031d9480d\n",
      "2025-05-12 21:54:19,092 - DEBUG - Top-level model cache MISS for schema_hash=dd570822454ef65617581ffaffd5db8d\n",
      "2025-05-12 21:54:19,092 - DEBUG - Building sub-model 'escalationtomanagement' from schema. key=submodel:e5a473778bc2a4b07d4239c38e891fdd\n",
      "2025-05-12 21:54:19,093 - INFO - Dynamic models created for parallel tools mode.\n",
      "2025-05-12 21:54:19,093 - INFO - LLMClientHub initialized successfully.\n",
      "2025-05-12 21:54:19,093 - ERROR - typing.Iterable[typing.Union[llm_client.utils.dynamic_model_creator.issueresolution, llm_client.utils.dynamic_model_creator.damagedproduct, llm_client.utils.dynamic_model_creator.poorcustomersupport, llm_client.utils.dynamic_model_creator.refunddelay, llm_client.utils.dynamic_model_creator.agentcommunicationissues, llm_client.utils.dynamic_model_creator.escalationtomanagement]]\n",
      "2025-05-12 21:54:19,094 - DEBUG - Handling response for message: system_prompt_template='You are a helpful assistant that analyzes customer summaries to identify relevant topics.\\nPROCESS:\\n1. Read the provided customer summary carefully\\n2. Select ONLY topics with higher relevance to the summary\\n3. YOU MUST USE FUNCTION CALLING for each relevant topic\\n4. DO NOT return free text lists - ONLY use the appropriate function tools\\n\\nFor each relevant topic, call the corresponding function tool.\\n\\nEXAMPLES:\\n    \\nSummary 1:\\n\"Customer is upset due to a 6-day delivery delay and a scratched phone. Support was unhelpful. They\\'re requesting a refund or replacement. Human handover needed.\"\\n\\nHighly Relevant Topics:\\n-  Delivery Problems   \\n- Issue not solved\\n- No compensation given\\n\\nSummary 2:\\n\"Customer frustrated with support agent\\'s lengthy response times during order inquiry. Responses took 10-25 minutes each, turning a simple shipping status check into a 2-hour conversation. Customer expressed increasing irritation with the delayed communication.\"\\n\\nHighly Relevant Topics:\\n- Agent replied slowly\\n\\n\\n\\n' user_prompt_template='Analyze the following summary and identify the topics being discussed: {user_message}\\n\\nReturn ONLY the NAMES of topics with higher relevance to this summary using function calls.' user_message='Customer requested more information. Provided overview of Al-Nokhba Home Equipment Company: specializes in manufacturing and installing windows, doors, kitchens, wardrobes, stair barriers, and sanitary materials; experienced since 2009. Asked customer to specify what information they need.' message_context={'user_message': 'Customer requested more information. Provided overview of Al-Nokhba Home Equipment Company: specializes in manufacturing and installing windows, doors, kitchens, wardrobes, stair barriers, and sanitary materials; experienced since 2009. Asked customer to specify what information they need.'} output_schema=typing.Iterable[typing.Union[llm_client.utils.dynamic_model_creator.issueresolution, llm_client.utils.dynamic_model_creator.damagedproduct, llm_client.utils.dynamic_model_creator.poorcustomersupport, llm_client.utils.dynamic_model_creator.refunddelay, llm_client.utils.dynamic_model_creator.agentcommunicationissues, llm_client.utils.dynamic_model_creator.escalationtomanagement]] image_urls=[] with response type: structured_response\n",
      "2025-05-12 21:54:19,094 - DEBUG - Creating messages from llm_message: system_prompt_template='You are a helpful assistant that analyzes customer summaries to identify relevant topics.\\nPROCESS:\\n1. Read the provided customer summary carefully\\n2. Select ONLY topics with higher relevance to the summary\\n3. YOU MUST USE FUNCTION CALLING for each relevant topic\\n4. DO NOT return free text lists - ONLY use the appropriate function tools\\n\\nFor each relevant topic, call the corresponding function tool.\\n\\nEXAMPLES:\\n    \\nSummary 1:\\n\"Customer is upset due to a 6-day delivery delay and a scratched phone. Support was unhelpful. They\\'re requesting a refund or replacement. Human handover needed.\"\\n\\nHighly Relevant Topics:\\n-  Delivery Problems   \\n- Issue not solved\\n- No compensation given\\n\\nSummary 2:\\n\"Customer frustrated with support agent\\'s lengthy response times during order inquiry. Responses took 10-25 minutes each, turning a simple shipping status check into a 2-hour conversation. Customer expressed increasing irritation with the delayed communication.\"\\n\\nHighly Relevant Topics:\\n- Agent replied slowly\\n\\n\\n\\n' user_prompt_template='Analyze the following summary and identify the topics being discussed: {user_message}\\n\\nReturn ONLY the NAMES of topics with higher relevance to this summary using function calls.' user_message='Customer requested more information. Provided overview of Al-Nokhba Home Equipment Company: specializes in manufacturing and installing windows, doors, kitchens, wardrobes, stair barriers, and sanitary materials; experienced since 2009. Asked customer to specify what information they need.' message_context={'user_message': 'Customer requested more information. Provided overview of Al-Nokhba Home Equipment Company: specializes in manufacturing and installing windows, doors, kitchens, wardrobes, stair barriers, and sanitary materials; experienced since 2009. Asked customer to specify what information they need.'} output_schema=typing.Iterable[typing.Union[llm_client.utils.dynamic_model_creator.issueresolution, llm_client.utils.dynamic_model_creator.damagedproduct, llm_client.utils.dynamic_model_creator.poorcustomersupport, llm_client.utils.dynamic_model_creator.refunddelay, llm_client.utils.dynamic_model_creator.agentcommunicationissues, llm_client.utils.dynamic_model_creator.escalationtomanagement]] image_urls=[] and response_type: structured_response\n",
      "2025-05-12 21:54:19,094 - DEBUG - Formatted system prompt: You are a helpful assistant that analyzes customer summaries to identify relevant topics.\n",
      "PROCESS:\n",
      "1. Read the provided customer summary carefully\n",
      "2. Select ONLY topics with higher relevance to the summary\n",
      "3. YOU MUST USE FUNCTION CALLING for each relevant topic\n",
      "4. DO NOT return free text lists - ONLY use the appropriate function tools\n",
      "\n",
      "For each relevant topic, call the corresponding function tool.\n",
      "\n",
      "EXAMPLES:\n",
      "    \n",
      "Summary 1:\n",
      "\"Customer is upset due to a 6-day delivery delay and a scratched phone. Support was unhelpful. They're requesting a refund or replacement. Human handover needed.\"\n",
      "\n",
      "Highly Relevant Topics:\n",
      "-  Delivery Problems   \n",
      "- Issue not solved\n",
      "- No compensation given\n",
      "\n",
      "Summary 2:\n",
      "\"Customer frustrated with support agent's lengthy response times during order inquiry. Responses took 10-25 minutes each, turning a simple shipping status check into a 2-hour conversation. Customer expressed increasing irritation with the delayed communication.\"\n",
      "\n",
      "Highly Relevant Topics:\n",
      "- Agent replied slowly\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2025-05-12 21:54:19,095 - DEBUG - Formatted user prompt: Analyze the following summary and identify the topics being discussed: Customer requested more information. Provided overview of Al-Nokhba Home Equipment Company: specializes in manufacturing and installing windows, doors, kitchens, wardrobes, stair barriers, and sanitary materials; experienced since 2009. Asked customer to specify what information they need.\n",
      "\n",
      "Return ONLY the NAMES of topics with higher relevance to this summary using function calls.\n",
      "2025-05-12 21:54:19,095 - DEBUG - Generated messages: [{'role': 'system', 'content': 'You are a helpful assistant that analyzes customer summaries to identify relevant topics.\\nPROCESS:\\n1. Read the provided customer summary carefully\\n2. Select ONLY topics with higher relevance to the summary\\n3. YOU MUST USE FUNCTION CALLING for each relevant topic\\n4. DO NOT return free text lists - ONLY use the appropriate function tools\\n\\nFor each relevant topic, call the corresponding function tool.\\n\\nEXAMPLES:\\n    \\nSummary 1:\\n\"Customer is upset due to a 6-day delivery delay and a scratched phone. Support was unhelpful. They\\'re requesting a refund or replacement. Human handover needed.\"\\n\\nHighly Relevant Topics:\\n-  Delivery Problems   \\n- Issue not solved\\n- No compensation given\\n\\nSummary 2:\\n\"Customer frustrated with support agent\\'s lengthy response times during order inquiry. Responses took 10-25 minutes each, turning a simple shipping status check into a 2-hour conversation. Customer expressed increasing irritation with the delayed communication.\"\\n\\nHighly Relevant Topics:\\n- Agent replied slowly\\n\\n\\n\\n'}, {'role': 'user', 'content': 'Analyze the following summary and identify the topics being discussed: Customer requested more information. Provided overview of Al-Nokhba Home Equipment Company: specializes in manufacturing and installing windows, doors, kitchens, wardrobes, stair barriers, and sanitary materials; experienced since 2009. Asked customer to specify what information they need.\\n\\nReturn ONLY the NAMES of topics with higher relevance to this summary using function calls.'}]\n",
      "2025-05-12 21:54:19,095 - DEBUG - System prompt: You are a helpful assistant that analyzes customer summaries to identify relevant topics.\n",
      "PROCESS:\n",
      "1. Read the provided customer summary carefully\n",
      "2. Select ONLY topics with higher relevance to the summary\n",
      "3. YOU MUST USE FUNCTION CALLING for each relevant topic\n",
      "4. DO NOT return free text lists - ONLY use the appropriate function tools\n",
      "\n",
      "For each relevant topic, call the corresponding function tool.\n",
      "\n",
      "EXAMPLES:\n",
      "    \n",
      "Summary 1:\n",
      "\"Customer is upset due to a 6-day delivery delay and a scratched phone. Support was unhelpful. They're requesting a refund or replacement. Human handover needed.\"\n",
      "\n",
      "Highly Relevant Topics:\n",
      "-  Delivery Problems   \n",
      "- Issue not solved\n",
      "- No compensation given\n",
      "\n",
      "Summary 2:\n",
      "\"Customer frustrated with support agent's lengthy response times during order inquiry. Responses took 10-25 minutes each, turning a simple shipping status check into a 2-hour conversation. Customer expressed increasing irritation with the delayed communication.\"\n",
      "\n",
      "Highly Relevant Topics:\n",
      "- Agent replied slowly\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2025-05-12 21:54:19,114 - DEBUG - max_retries: 3\n",
      "2025-05-12 21:54:19,115 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x12b3ecf80>\n",
      "2025-05-12 21:54:19,120 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-91cabe15-dbf3-4a34-b05b-3e4f8f2a486d', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant that analyzes customer summaries to identify relevant topics.\\nPROCESS:\\n1. Read the provided customer summary carefully\\n2. Select ONLY topics with higher relevance to the summary\\n3. YOU MUST USE FUNCTION CALLING for each relevant topic\\n4. DO NOT return free text lists - ONLY use the appropriate function tools\\n\\nFor each relevant topic, call the corresponding function tool.\\n\\nEXAMPLES:\\n    \\nSummary 1:\\n\"Customer is upset due to a 6-day delivery delay and a scratched phone. Support was unhelpful. They\\'re requesting a refund or replacement. Human handover needed.\"\\n\\nHighly Relevant Topics:\\n-  Delivery Problems   \\n- Issue not solved\\n- No compensation given\\n\\nSummary 2:\\n\"Customer frustrated with support agent\\'s lengthy response times during order inquiry. Responses took 10-25 minutes each, turning a simple shipping status check into a 2-hour conversation. Customer expressed increasing irritation with the delayed communication.\"\\n\\nHighly Relevant Topics:\\n- Agent replied slowly\\n\\n\\n\\n'}, {'role': 'user', 'content': 'Analyze the following summary and identify the topics being discussed: Customer requested more information. Provided overview of Al-Nokhba Home Equipment Company: specializes in manufacturing and installing windows, doors, kitchens, wardrobes, stair barriers, and sanitary materials; experienced since 2009. Asked customer to specify what information they need.\\n\\nReturn ONLY the NAMES of topics with higher relevance to this summary using function calls.'}], 'model': 'gpt-4o-mini', 'max_tokens': 1000, 'temperature': 0, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'issueresolution', 'description': 'Correctly extracted `issueresolution` with all the required parameters with correct types', 'parameters': {'properties': {'description': {'title': 'Description', 'type': 'string'}}, 'required': ['description'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'damagedproduct', 'description': 'Correctly extracted `damagedproduct` with all the required parameters with correct types', 'parameters': {'properties': {'description': {'title': 'Description', 'type': 'string'}}, 'required': ['description'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'poorcustomersupport', 'description': 'Correctly extracted `poorcustomersupport` with all the required parameters with correct types', 'parameters': {'properties': {'description': {'title': 'Description', 'type': 'string'}}, 'required': ['description'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'refunddelay', 'description': 'Correctly extracted `refunddelay` with all the required parameters with correct types', 'parameters': {'properties': {'description': {'title': 'Description', 'type': 'string'}}, 'required': ['description'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'agentcommunicationissues', 'description': 'Correctly extracted `agentcommunicationissues` with all the required parameters with correct types', 'parameters': {'properties': {'description': {'title': 'Description', 'type': 'string'}}, 'required': ['description'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'escalationtomanagement', 'description': 'Correctly extracted `escalationtomanagement` with all the required parameters with correct types', 'parameters': {'properties': {'description': {'title': 'Description', 'type': 'string'}}, 'required': ['description'], 'type': 'object'}}}]}}\n",
      "2025-05-12 21:54:19,120 - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "2025-05-12 21:54:19,124 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2025-05-12 21:54:19,402 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x12fa2b2c0>\n",
      "2025-05-12 21:54:19,403 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x12be1aad0> server_hostname='api.openai.com' timeout=5.0\n",
      "2025-05-12 21:54:19,419 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1393eade0>\n",
      "2025-05-12 21:54:19,420 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-05-12 21:54:19,421 - DEBUG - send_request_headers.complete\n",
      "2025-05-12 21:54:19,421 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-05-12 21:54:19,422 - DEBUG - send_request_body.complete\n",
      "2025-05-12 21:54:19,423 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-05-12 21:54:22,481 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 12 May 2025 17:54:22 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-mv8fptk1msbbkcb9c2lz30zv'), (b'openai-processing-ms', b'1378'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'1381'), (b'x-ratelimit-limit-requests', b'30000'), (b'x-ratelimit-limit-tokens', b'150000000'), (b'x-ratelimit-remaining-requests', b'29999'), (b'x-ratelimit-remaining-tokens', b'149999630'), (b'x-ratelimit-reset-requests', b'2ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_6d91ffcf4739942c9c2dcfbd94c02405'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=hiA5rn25wwu.7bg3Wds1QBWcUHC_fqnWzbu2OklcssE-1747072462-1.0.1.1-xGku86RVHR1rdNSA45Es69NXSYYygm4E7CnDrQDtkbUp3npOx1hKJ_Oo0By3qmNVZOu7RufBQdxw6o0_2R6__YIvEQwKyYjaSCkruall7QI; path=/; expires=Mon, 12-May-25 18:24:22 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=scOT913iwv4gReApmCrpIJWQ3UONJoam4ExSBTTWaMQ-1747072462646-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'93ebc7d8ebe9c951-MCT'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2025-05-12 21:54:22,483 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-05-12 21:54:22,484 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-05-12 21:54:22,487 - DEBUG - receive_response_body.complete\n",
      "2025-05-12 21:54:22,488 - DEBUG - response_closed.started\n",
      "2025-05-12 21:54:22,489 - DEBUG - response_closed.complete\n",
      "2025-05-12 21:54:22,490 - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Mon, 12 May 2025 17:54:22 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-mv8fptk1msbbkcb9c2lz30zv'), ('openai-processing-ms', '1378'), ('openai-version', '2020-10-01'), ('x-envoy-upstream-service-time', '1381'), ('x-ratelimit-limit-requests', '30000'), ('x-ratelimit-limit-tokens', '150000000'), ('x-ratelimit-remaining-requests', '29999'), ('x-ratelimit-remaining-tokens', '149999630'), ('x-ratelimit-reset-requests', '2ms'), ('x-ratelimit-reset-tokens', '0s'), ('x-request-id', 'req_6d91ffcf4739942c9c2dcfbd94c02405'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=hiA5rn25wwu.7bg3Wds1QBWcUHC_fqnWzbu2OklcssE-1747072462-1.0.1.1-xGku86RVHR1rdNSA45Es69NXSYYygm4E7CnDrQDtkbUp3npOx1hKJ_Oo0By3qmNVZOu7RufBQdxw6o0_2R6__YIvEQwKyYjaSCkruall7QI; path=/; expires=Mon, 12-May-25 18:24:22 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=scOT913iwv4gReApmCrpIJWQ3UONJoam4ExSBTTWaMQ-1747072462646-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '93ebc7d8ebe9c951-MCT'), ('content-encoding', 'br'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "2025-05-12 21:54:22,491 - DEBUG - request_id: req_6d91ffcf4739942c9c2dcfbd94c02405\n",
      "2025-05-12 21:54:22,500 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-BWRe1SoK27WNGJIG7MeCJsSVrTiyi', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_71lUarjYA8xmC174wSDbXpjL', function=Function(arguments='{\"description\": \"Customer requested more information from the support agent.\"}', name='agentcommunicationissues'), type='function'), ChatCompletionMessageToolCall(id='call_7VbJSgbwrTNc5Xy4CYtz2KtC', function=Function(arguments='{\"description\": \"Customer asked for specific information regarding products and services.\"}', name='escalationtomanagement'), type='function')]))], created=1747072461, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_dbaca60df0', usage=CompletionUsage(completion_tokens=67, prompt_tokens=511, total_tokens=578, completion_tokens_details=None, prompt_tokens_details=None))\n",
      "2025-05-12 21:54:22,501 - DEBUG - Returning model from ParallelBase\n",
      "2025-05-12 21:54:22,502 - DEBUG - Structured response: [agentcommunicationissues(description='Customer requested more information from the support agent.'), escalationtomanagement(description='Customer asked for specific information regarding products and services.')]\n",
      "2025-05-12 21:54:22,502 - DEBUG - Raw completion: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: [agentcommunicationissues(description='Customer requested more information from the support agent.'), escalationtomanagement(description='Customer asked for specific information regarding products and services.')]\n",
      "Execution time: 3.62 seconds\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "import traceback\n",
    "from typing import List, Dict, Any\n",
    "import time\n",
    "import nest_asyncio\n",
    "from pydantic import BaseModel, Field, create_model\n",
    "import re\n",
    "from openai import OpenAI\n",
    "from llm_client.hub import LLMClientHub\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "sys_prompt_template = \"\"\"You are a helpful assistant that analyzes customer summaries to identify relevant topics.\n",
    "PROCESS:\n",
    "1. Read the provided customer summary carefully\n",
    "2. Select ONLY topics with higher relevance to the summary\n",
    "3. YOU MUST USE FUNCTION CALLING for each relevant topic\n",
    "4. DO NOT return free text lists - ONLY use the appropriate function tools\n",
    "\n",
    "For each relevant topic, call the corresponding function tool.\n",
    "\n",
    "EXAMPLES:\n",
    "    \n",
    "Summary 1:\n",
    "\"Customer is upset due to a 6-day delivery delay and a scratched phone. Support was unhelpful. They're requesting a refund or replacement. Human handover needed.\"\n",
    "\n",
    "Highly Relevant Topics:\n",
    "-  Delivery Problems   \n",
    "- Issue not solved\n",
    "- No compensation given\n",
    "\n",
    "Summary 2:\n",
    "\"Customer frustrated with support agent's lengthy response times during order inquiry. Responses took 10-25 minutes each, turning a simple shipping status check into a 2-hour conversation. Customer expressed increasing irritation with the delayed communication.\"\n",
    "\n",
    "Highly Relevant Topics:\n",
    "- Agent replied slowly\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "user_prompt_template = \"\"\"Analyze the following summary and identify the topics being discussed: {user_message}\n",
    "\n",
    "Return ONLY the NAMES of topics with higher relevance to this summary using function calls.\"\"\"\n",
    "\n",
    "def create_topic_schema(topic_list: List[str]) -> List[Dict]:\n",
    "   schema_dict = []\n",
    "   for topic in topic_list:\n",
    "       # Create model name: lowercase with no special chars or spaces\n",
    "       model_name = re.sub(r'[^a-zA-Z0-9]', '', topic).lower()\n",
    "       # Create schema\n",
    "       schema = {\n",
    "           'properties': {\n",
    "               'description': {\n",
    "                   'description': topic,\n",
    "                   'title': 'Description',\n",
    "                   'type': 'string'\n",
    "               }\n",
    "           },\n",
    "           'required': ['description'],\n",
    "           'title': model_name,\n",
    "           'type': 'object'\n",
    "       }\n",
    "       schema_dict.append(schema)\n",
    "   return schema_dict\n",
    "\n",
    "# Topic list\n",
    "topics = [\"Issue resolution\", \"Damaged product\", \"Poor customer support\", \n",
    "         \"Refund delay\", \"Agent communication issues\", \"Escalation to management\"]\n",
    "\n",
    "# Create schemas\n",
    "dynamic_models = create_topic_schema(topics)\n",
    "\n",
    "# Convert dynamic models to proper OpenAI tool format\n",
    "def create_tools(schemas):\n",
    "   tools = []\n",
    "   for schema in schemas:\n",
    "       tools.append({\n",
    "           \"type\": \"function\",\n",
    "           \"function\": {\n",
    "               \"name\": schema[\"title\"],\n",
    "               \"description\": f\"Identify if {schema['properties']['description']['description']} is relevant\",\n",
    "               \"parameters\": schema\n",
    "           }\n",
    "       })\n",
    "   return tools\n",
    "\n",
    "\n",
    "def create_config(dynamic_models):\n",
    "   \n",
    "   tools = create_tools(dynamic_models)\n",
    "   \n",
    "   return {\n",
    "       \"model\": {\n",
    "           \"provider\": \"openai\",\n",
    "           \"model\": \"gpt-4o-mini\",\n",
    "           \"temperature\": 0,\n",
    "           \"max_tokens\": 1000,\n",
    "           \"mode\": \"PARALLEL_TOOLS\",\n",
    "           \"tool_choice\": \"required\"  \n",
    "       },\n",
    "       \"sys_tmpl\": sys_prompt_template,\n",
    "       \"usr_tmpl\": user_prompt_template,\n",
    "       \"response_type\": \"structured_response\",\n",
    "       \"DynamicModel\": dynamic_models,\n",
    "       \"tools\": tools  \n",
    "   }\n",
    "\n",
    "async def main():\n",
    "   try:\n",
    "       start_time = time.time()\n",
    "       \n",
    "       context = {\n",
    "           \"user_message\": \"Customer requested more information. Provided overview of Al-Nokhba Home Equipment Company: specializes in manufacturing and installing windows, doors, kitchens, wardrobes, stair barriers, and sanitary materials; experienced since 2009. Asked customer to specify what information they need.\"\n",
    "       }\n",
    "       \n",
    "       config = create_config(dynamic_models)\n",
    "       \n",
    "       logger.debug(f\"Tools: {json.dumps(config['tools'][0], indent=2)}\")\n",
    "       \n",
    "       llm_client_hub = LLMClientHub(config)\n",
    "       \n",
    "       response, raw_completion = await llm_client_hub.handle_response(context)\n",
    "       \n",
    "       print(\"Response:\", response)\n",
    "       print(f\"Execution time: {time.time() - start_time:.2f} seconds\")\n",
    "       \n",
    "       return {\"response\": response, \"raw_completion\": raw_completion}\n",
    "       \n",
    "   except Exception as e:\n",
    "       logger.error(f\"Error during execution: {e}\")\n",
    "       logger.error(traceback.format_exc())\n",
    "       return {\"error\": str(e)}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   try:\n",
    "       \n",
    "       nest_asyncio.apply()\n",
    "       \n",
    "       \n",
    "       loop = asyncio.get_event_loop()\n",
    "       \n",
    "       if loop.is_running():\n",
    "           logger.info(\"Event loop is already running. Using create_task instead.\")\n",
    "           task = asyncio.create_task(main())\n",
    "           \n",
    "       else:\n",
    "           result = loop.run_until_complete(main())\n",
    "           print(\"Result:\", result)\n",
    "           \n",
    "   except Exception as e:\n",
    "       logger.error(f\"Error during execution: {e}\")\n",
    "       logger.error(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
